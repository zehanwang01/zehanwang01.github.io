# üìù Representative Publications 
## Unified Multimodal Perception
- Unified Representations: **C-MCR (NeurIPS 2023)**, **Ex-MCR (NeurIPS 2024)**, **FreeBind (ICML 2024)**, **OmniBind (ICLR 2025)**

## Spatial Intelligence in Visual Content

- Point Cloud Understanding: **Chat-3D (NAACL 2023) / Chat-Scene (NeurIPS 2024)** for 3D MLLM, **3DRP-Net (EMNLP 2023) / WS-3DVG (ICCV 2023)** for 3D visual grounding.

- Spatial-aware Image Understanding: **Orient Anything (ICML 2025)**, **SpatialCLIP (CVPR 2025)**

- Spatial-aware Image Generation: **6DoF-Gen (Working on)**, **GenSpace (Working on)**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2025</div><img src='images/prior_depth.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [Depth Anything with Any Prior.](https://prior-depth-anything.github.io/) **Zehan Wang**, Siyu Chen, Lihe Yang, Jialei Wang, Ziang Zhang, Hengshuang Zhao, Zhou Zhao      **Arxiv, 2025**
- The SoTA **zero-shot** depth estimation model that can integrate any form of depth measurement as prior. [![](https://img.shields.io/github/stars/SpatialVision/Prior-Depth-Anything?style=social&label=Code+Stars)](https://github.com/SpatialVision/Prior-Depth-Anything)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2025</div><img src='images/Orient-anything.jpeg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [Orient Anything: Learning Robust Object Orientation Estimation from Rendering 3D Models.](https://orient-anything.github.io/) **Zehan Wang**, Ziang Zhang, Tianyu Pang, Chao Du, Hengshuang Zhao, Zhou Zhao **ICML, 2025**
- The first **zero-shot** image-based object orientation estimation model. [![](https://img.shields.io/github/stars/SpatialVision/Orient-Anything?style=social&label=Code+Stars)](https://github.com/SpatialVision/Orient-Anything)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025</div><img src='images/spatialCLIP.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [SpatialCLIP: Learning 3D-aware Image Representations from Spatially Discriminative Language.]() **Zehan Wang**, Sashuai zhou, Shaoxuan He, Haifeng Huang, Lihe Yang, Ziang Zhang, Xize Cheng, Shengpeng Ji, Tao Jin, Hengshuang Zhao, Zhou Zhao **CVPR, 2025**
- Improving spatial intelligence of MLLM by enhancing the CLIP visual representations.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/chat-scene.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [Chat-3d: Data-efficiently tuning large language model for universal dialogue of 3d scenes](https://arxiv.org/pdf/2308.08769) **Zehan Wang**\*, Haifeng Huang\*, Yang Zhao, Ziang Zhang, Zhou Zhao **NAACL 2025**
- [Chat-scene: Bridging 3d scene and large language models with object identifiers](https://openreview.net/pdf?id=t3BhmwAzhv) Haifeng Huang\*, Yilun Chen\*, **Zehan Wang**\*, Rongjie Huang, Runsen Xu, Tai Wang, Luping Liu, Xize Cheng, Yang Zhao, Jiangmiao Pang, Zhou Zhao **NeurIPS 2024**
- Series of state-of-the-art 3D MLLM for scene understanding. [![](https://img.shields.io/github/stars/ZzZZCHS/Chat-Scene?style=social&label=Code+Stars)](https://github.com/ZzZZCHS/Chat-Scene)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2025</div><img src='images/ICLR2025_OmniBind.jpeg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [Omnibind: Large-scale omni multimodal representation via binding spaces](https://arxiv.org/pdf/2407.11895?) **Zehan Wang**, Ziang Zhang, Hang Zhang, Luping Liu, Rongjie Huang, Xize Cheng, Hengshuang Zhao, Zhou Zhao **ICLR 2025**
- Large-scale 3D-audio-image-language representation models (7B‚Äì30B parameters) achieving SoTA performance on 13 benchmarks.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2024</div><img src='images/ICML2024.jpeg' alt="sym" width="70%"></div></div>
<div class='paper-box-text' markdown="1">

- [FreeBind: Free Lunch in Unified Multimodal Space via Knowledge Fusion](https://arxiv.org/pdf/2405.04883) **Zehan Wang**, Ziang Zhang, Xize Cheng, Rongjie Huang, Luping Liu, Zhenhui Ye, Haifeng Huang, Yang Zhao, Tao Jin, Peng Gao, Zhou Zhao **ICML 2024**
- Enhancing multimodal representations (e.g., ImageBind, InternVL) by freely fusing them in a unified space.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='images/NeurIPS2023.jpeg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [Connecting Multi-modal Contrastive Representations](https://proceedings.neurips.cc/paper_files/paper/2023/file/46362971bfc3a97e6a271f2eb90fba17-Paper-Conference.pdf) **Zehan Wang**, Yang Zhao, Xize Cheng, Haifeng Huang, Jiageng Liu, Li Tang, Linjun Li, Yongqi Wang, Aoxiong Yin, Ziang Zhang, Zhou Zhao **NeurIPS 2023**
- Learning multimodal contrastive representations without requiring paired data.
</div>
</div>

# Full Publication List

## 2025
- ``Arxiv 2025`` [Orient Anything: Learning Robust Object Orientation Estimation from Rendering 3D Models](https://arxiv.org/pdf/2412.18605?) **Zehan Wang**, Ziang Zhang, Tianyu Pang, Chao Du, Hengshuang Zhao, Zhou Zhao
- ``Arxiv 2025`` [OmniChat: Enhancing Spoken Dialogue Systems with Scalable Synthetic Data for Diverse Scenarios](https://arxiv.org/pdf/2501.01384) **Zehan Wang**, Haifeng Huang, Yang Zhao, Ziang Zhang, Zhou Zhao
- ``CVPR 2025`` [SpatialCLIP: Learning 3D-aware Image Representations from Spatially Discriminative Language.]()  **Zehan Wang**, Sashuai zhou, Shaoxuan He, Haifeng Huang, Lihe Yang, Ziang Zhang, Xize Cheng, Shengpeng Ji, Tao Jin, Hengshuang Zhao, Zhou Zhao
- ``CVPR 2025`` [RoboGround: Robot Manipulation with Grounded Vision-Language Priors] Haifeng Huang, Xinyi Chen, Yilun Chen, Hao Li, Xiaoshen Han, **Zehan Wang**, Tai Wang, Jiangmiao Pang, Zhou Zhao
- ``NAACL 2025`` [Chat-3d: Data-efficiently tuning large language model for universal dialogue of 3d scenes](https://arxiv.org/pdf/2308.08769) **Zehan Wang**\*, Haifeng Huang\*, Yang Zhao, Ziang Zhang, Zhou Zhao
- ``WWW 2025`` [EAGER-LLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration](https://arxiv.org/pdf/2502.14735?) Minjie Hong, Yan Xia, **Zehan Wang**, Jieming Zhu, Ye Wang, Sihang Cai, Xiaoda Yang, Quanyu Dai, Zhenhua Dong, Zhimeng Zhang, Zhou Zhao
- ``ICLR 2025`` [Omnibind: Large-scale omni multimodal representation via binding spaces](https://arxiv.org/pdf/2407.11895?) **Zehan Wang**, Ziang Zhang, Hang Zhang, Luping Liu, Rongjie Huang, Xize Cheng, Hengshuang Zhao, Zhou Zhao
- ``ICLR 2025`` [Improving Long-Text Alignment for Text-to-Image Diffusion Models](https://arxiv.org/pdf/2410.11817?) Luping Liu, Chao Du, Tianyu Pang, **Zehan Wang**, Chongxuan Li, Dong Xu
- ``ICLR 2025`` [OmniSep: Unified Omni-Modality Sound Separation with Query-Mixup](https://arxiv.org/pdf/2410.21269) Xize Cheng, Siqi Zheng, **Zehan Wang**, Minghui Fang, Ziang Zhang, Rongjie Huang, Ziyang Ma, Shengpeng Ji, Jialong Zuo, Tao Jin, Zhou Zhao
- ``ICLR 2025`` [VoxDialogue: Can Spoken Dialogue Systems Understand Information Beyond Words?](https://openreview.net/pdf?id=vbmSSIhKAM) Xize Cheng, Ruofan Hu, Xiaoda Yang, Jingyu Lu, Dongjie Fu, **Zehan Wang**, Shengpeng Ji, Rongjie Huang, Boyang Zhang, Tao Jin, Zhou Zhao
- ``ICLR 2025`` [Wavtokenizer: an efficient acoustic discrete codec tokenizer for audio language modeling](https://arxiv.org/pdf/2408.16532) Shengpeng Ji, Ziyue Jiang, Wen Wang, Yifu Chen, Minghui Fang, Jialong Zuo, Qian Yang, Xize Cheng, **Zehan Wang**, Ruiqi Li, Ziang Zhang, Xiaoda Yang, Rongjie Huang, Yidi Jiang, Qian Chen, Siqi Zheng, Zhou Zhao
- ``ICLR 2025`` [Diff-prompt: Diffusion-driven prompt generator with mask supervision]() Weicai Yan, Wang Lin, Zirun Guo, Ye Wang, Fangming Feng, Xiaoda Yang, **Zehan Wang**, Tao Jin

## 2024
- ``NeurIPS 2024`` [Chat-scene: Bridging 3d scene and large language models with object identifiers](https://openreview.net/pdf?id=t3BhmwAzhv) Haifeng Huang\*, Yilun Chen\*, **Zehan Wang**\*, Rongjie Huang, Runsen Xu, Tai Wang, Luping Liu, Xize Cheng, Yang Zhao, Jiangmiao Pang, Zhou Zhao
- ``NeurIPS 2024`` [Extending multi-modal contrastive representations](https://proceedings.neurips.cc/paper_files/paper/2024/file/a71df365f872a39e58475f1fa7950879-Paper-Conference.pdf) Ziang Zhang\*, Zehan Wang\*, Luping Liu, Rongjie Huang, Xize Cheng, Zhenhui Ye, Wang Lin, Huadai Liu, Haifeng Huang, Yang Zhao, Tao Jin, Siqi Zheng, Zhou Zhao
- ``NeurIPS 2024`` [MimicTalk: Mimicking a personalized and expressive 3D talking face in minutes]() Zhenhui Ye, Tianyun Zhong, Yi Ren, Ziyue Jiang, Jiawei Huang, Rongjie Huang, Jinglin Liu, Jinzheng He, Chen Zhang, **Zehan Wang**, Xize Chen, Xiang Yin, Zhou Zhao
- ``NeurIPS 2024`` [Lumina-Next: Making Lumina-T2X Stronger and Faster with Next-DiT]() Le Zhuo, Ruoyi Du, Han Xiao, Yangguang Li, Dongyang Liu, Rongjie Huang, Wenze Liu, Lirui Zhao, Fu-Yun Wang, Zhanyu Ma, Xu Luo, **Zehan Wang**, Kaipeng Zhang, Xiangyang Zhu, Si Liu, Xiangyu Yue, Dingning Liu, Wanli Ouyang, Ziwei Liu, Yu Qiao, Hongsheng Li, Peng Gao
- ``NeurIPS 2024`` [Frieren: Efficient Video-to-Audio Generation with Rectified Flow Matching]() Yongqi Wang, Wenxiang Guo, Rongjie Huang, Jiawei Huang, **Zehan Wang**, Fuming You, Ruiqi Li, Zhou Zhao
- ``NeurIPS 2024`` [Action Imitation in Common Action Space for Customized Action Image Synthesis]() Wang Lin, Jingyuan Chen, Jiaxin Shi, Zirun Guo, Yichen Zhu, **Zehan Wang**, Tao Jin, Zhou Zhao, Fei Wu, YAN Shuicheng, Hanwang Zhang
- ``ICML 2024`` [FreeBind: Free Lunch in Unified Multimodal Space via Knowledge Fusion](https://arxiv.org/abs/2405.04883) **Zehan Wang**, Ziang Zhang, Xize Cheng, Rongjie Huang, Luping Liu, Zhenhui Ye, Haifeng Huang, Yang Zhao, Tao Jin, Peng Gao, Zhou Zhao
- ``ICML 2024`` [InstructSpeech: Following Speech Editing Instructions via Large Language Models]() Rongjie Huang, Ruofan Hu, Yongqi Wang, **Zehan Wang**, Xize Cheng, Ziyue Jiang, Zhenhui Ye, Dongchao Yang, Luping Liu, Peng Gao, Zhou Zhao
- ``ACL 2024`` [Make-a-voice: Revisiting voice large language models as scalable multilingual and multitask learners](https://aclanthology.org/2024.acl-long.589/) Rongjie Huang, Chunlei Zhang, Yongqi Wang, Dongchao Yang, Jinchuan Tian, Zhenhui Ye, Luping Liu, **Zehan Wang**, Ziyue Jiang, Xuankai Chang, Jiatong Shi, Chao Weng, Zhou Zhao, Dong Yu
- ``ACL 2024`` [TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head Translation](https://arxiv.org/abs/2312.15197) Xize Cheng, Rongjie Huang, Linjun Li, Tao Jin, **Zehan Wang**, Aoxiong Yin, Minglei Li, Xinyu Duan, Zhou Zhao
- ``ACM MM 2024`` [VoiceTuner: Self-Supervised Pre-training and Efficient Fine-tuning For Voice Generation](https://dl.acm.org/doi/abs/10.1145/3664647.3681695) Rongjie Huang, Yongqi Wang, Ruofan Hu, Xiaoshan Xu, Zhiqing Hong, Dongchao Yang, Xize Cheng, **Zehan Wang**, Ziyue Jiang, Zhenhui Ye, Luping Liu, Siqi Zheng, Zhou Zhao

## 2023
- ``NeurIPS 2023`` [Connecting Multi-modal Contrastive Representations.](https://arxiv.org/abs/2305.14381) **Zehan Wang**, Yang Zhao, Xize Cheng, Haifeng Huang, Jiageng Liu, Li Tang, Linjun Li, Yongqi Wang, Aoxiong Yin, Ziang Zhang, Zhou Zhao. NeurIPS 2023
- ``ICCV 2023`` [Distilling Coarse-to-Fine Semantic Matching Knowledge for Weakly Supervised 3D Visual Grounding.](https://arxiv.org/abs/2307.09267) **Zehan Wang**, Haifeng Huang, Yang Zhao, Linjun Li, Xize Cheng, Yichen Zhu, Aoxiong Yin, Zhou Zhao. ICCV 2023
- ``ICCV 2023`` [MixSpeech: Cross-Modality Self-Learning with Audio-Visual Stream Mixup for Visual Speech Translation and Recognition]() Xize Cheng, Tao Jin, Rongjie Huang, Linjun Li, Wang Lin, **Zehan Wang**, Ye Wang, Huadai Liu, Aoxiong Yin, Zhou Zhao. ICCV 2023
- ``EMNLP 2023`` [3DRP-Net: 3D Relative Position-aware Network for 3D Visual Grounding](https://arxiv.org/abs/2307.13363) **Zehan Wang**, Haifeng Huang, Yang Zhao, Linjun Li, Xize Cheng, Yichen Zhu, Aoxiong Yin, Zhou Zhao. EMNLP 2023
- ``ACL 2023`` [Scene-robust natural language video localization via learning domain-invariant representations](https://aclanthology.org/2023.findings-acl.11/) **Zehan Wang**, Yang Zhao, Haifeng Huang, Yan Xia, Zhou Zhao. ACL 2023
